{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XhNsAvHztpqo"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import imutils\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "personName = \"Jennie\"\n",
        "dataPath = \"/content/drive/MyDrive/phytton/ML/RECONOCIMIENTO FACIAL/Fotos/Jennie\" #ruta del data\n",
        "personPath = dataPath + \"/\" + personName"
      ],
      "metadata": {
        "id": "8ulA3dXyA7qH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(personPath):\n",
        "    print(\"Jennie:\",personPath)\n",
        "    os.makedirs(personPath)"
      ],
      "metadata": {
        "id": "ZYQnsOmaA7m7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(\"Video.mp4\")\n",
        "#para leer un video"
      ],
      "metadata": {
        "id": "F0MwDEmjA7i4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " faceClassif =cv2.CascadeClassifier(cv2.data.haarcascades+\"haarcascade_frontalface_default.xml\")\n",
        " count = 0"
      ],
      "metadata": {
        "id": "_dm3dfw1D55i"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if ret == False: break\n",
        "    frame = imutils.resize(frame, width=640)\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    auxFrame = frame.copy()\n",
        "\n",
        "    faces = faceClassif.detectMultiScale(gray,1.3,5)\n",
        "\n",
        "    for (x,y,w,h) in faces:\n",
        "        cv2.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)\n",
        "        rostro = auxFrame[y:y+h,x:x+w]\n",
        "        rostro = cv2.resize(rostro,(150,150),interpolation=cv2.INTER_CUBIC)\n",
        "        CV2.imwrite(personPath + \"/rostro_{}.JPG\".format(count),rostro)\n",
        "        count = count + 1\n",
        "    cv2.imshow(\"frame\",frame)    \n",
        "\n",
        "    k = cv2.waitKey(1)\n",
        "    if k == 27 or count >=300:\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()      \n"
      ],
      "metadata": {
        "id": "hs02wk8TD53H"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataPath = \"/content/drive/MyDrive/phytton/ML/RECONOCIMIENTO FACIAL/Fotos/Jennie\"\n",
        "\n",
        "peopleList = os.listdir(dataPath)\n",
        "print(\"Lista de personas: \", peopleList)\n",
        "\n",
        "labels = []\n",
        "facesData = []\n",
        "label = 0\n",
        "\n",
        "for nameDir in peopleList:\n",
        "    personPath = dataPath + \"/\" + nameDir\n",
        "    print(\"LLeyendo las imagenes\")\n",
        "\n",
        "    for fileName in os.listdir(personPath): \n",
        "        print(\"Rostros: \", nameDir + \"/\" + fileName)\n",
        "        labels.append(label)\n",
        "        facesData.append(cv2.imread(personPath+\"/\"+fileName,0))\n",
        "        image = cv2.imread(personPath+'/'+fileName,0)\n",
        "       \n",
        "    label = label + 1\n",
        "       \n",
        "\n",
        "print(\"labels= \",labels) \n",
        "#entrenando el reconocedor\n",
        "face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
        "\n",
        "\n",
        "print(\"Entrenando...\")\n",
        "face_recognizer.train(facesData, np.array(labels))"
      ],
      "metadata": {
        "id": "shAKu-EwD5xY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Almacenando el modelo\n",
        "face_recognizer.write('modeloLBPHFace.xml')\n",
        "print(\"Modelo almacenado...\")"
      ],
      "metadata": {
        "id": "Nh4rfZhnA7dF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KYnzoygAA7gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "38IxG_aIA7U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cq3Ni-hKlo7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BwXhPsOXlo5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KjhxmYMclox0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}