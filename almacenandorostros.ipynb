{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ArHTfSkFvaFS"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import imutils\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "personName = \"Jennie\"\n",
        "dataPath = \"/home/dalia/Pictures/ML/Jennie\""
      ],
      "metadata": {
        "id": "HURVVmHpvbNo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "personPath = dataPath + \"/\" + personName"
      ],
      "metadata": {
        "id": "CgCnOkuvvbIT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(personPath):\n",
        "        print(\"Carpeta creada: \",personPath)\n",
        "        os.makedirs(personPath)\n",
        "#video\n",
        "cap = cv2.VideoCapture(\"Video.mp4\")        "
      ],
      "metadata": {
        "id": "JS_1ZRiYvbDW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "faceClassif = cv2.CascadeClassifier(cv2.data.haarcascades+\"haarcascade_forntalface_default.xml\")\n",
        "count = 0"
      ],
      "metadata": {
        "id": "7K6mmxCWva_9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "        ret, frame = cap.read()\n",
        "        if ret == False: break\n",
        "        frame = imutils.resize(frame, width=640)\n",
        "        gray = cv2.cvtColor(frame, cv2.Color_BGR2GRAY)\n",
        "        auxFrame = frame.copy()\n",
        "\n",
        "        faces = cafeClassif.detectMultiScale(gray,1.3,5)\n",
        "\n",
        "        for (x,y,w,h) in faces:\n",
        "                 cv2.rectangle(frame, (x,y),(x+w,y+h),(0,255,0),2)\n",
        "                 rostro = auxFrame[y:y+h,x:x+w]\n",
        "                 rostro = cv2.resize(rostro,(150,150),interpolation=cv2.INTER_CUBIC)\n",
        "                 cv2.imwrite(personPath + \"/rostro_{}.jpg\".format(count),rostro)\n",
        "                 count = count + 1\n",
        "        cv2_imshow(frame)\n",
        "\n",
        "        k = cv2.waitKey(1)\n",
        "        if k == 27 or count >= 300:\n",
        "                break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLmNwUPJwXYQ",
        "outputId": "0f41820c-3d88-4aa0-a27d-4bd926459575"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function destroyAllWindows>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CJvZp5x5wXTb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Aymf12I0wXQH"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}